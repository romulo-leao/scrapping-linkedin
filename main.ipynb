{"cells":[{"cell_type":"markdown","source":["# Coletando dados da página de funcionários de uma empresa no linkedin"],"metadata":{"id":"V7UCM7NvxSw1"}},{"cell_type":"markdown","source":["Neste projeto, iremos utilizar o selenium para coletar dados da página de funcionários de uma empresa no linkedin. No exemplo, a empresa em questão é a ClearSale, empresa em que trabalho como Especialista de People Analytics, e os dados que iremos coletar serão:\n","\n","\n","*   Nome do Perfil\n","*   URL do Perfil\n","*   Localização do Perfil\n","*   Títulos do Perfil\n","\n"],"metadata":{"id":"HnU6gWrXxZTp"}},{"cell_type":"markdown","source":["## Instalando e Importando as Dependências:"],"metadata":{"id":"xi1a9-cGyAac"}},{"cell_type":"code","source":["!pip install selenium"],"metadata":{"id":"bdEy78CVx_rG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLPGhF4bxGQ2"},"outputs":[],"source":["from selenium import webdriver\n","from getpass import getpass\n","from time import sleep\n","import pandas as pd"]},{"cell_type":"markdown","source":["## Abrindo o Navegador:"],"metadata":{"id":"aoyOd5wGyLuN"}},{"cell_type":"markdown","source":["*   É necesário fazer o download do Chromedriver com a versão compatível do seu navegador e deixá-lo no mesmo path do arquivo que deseja executar.\n","*   Caso não teha feito o download, este é o link : https://chromedriver.chromium.org/downloads"],"metadata":{"id":"skdu9pL-yQic"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yDfB6LyxGQ9"},"outputs":[],"source":["driver = webdriver.Chrome(r\"C:\\Users\\Romulo\\Desktop\\chromedriver.exe\")"]},{"cell_type":"markdown","source":["Neste momento, iremos pedir que o navegador acesse a URL do Linkedin:"],"metadata":{"id":"V86f-oMXydos"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8meUKbpxGQ-"},"outputs":[],"source":["url = 'http://www.linkedin.com'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lzBzQ9FxGQ_"},"outputs":[],"source":["driver.get(url)"]},{"cell_type":"markdown","source":["## Instanciando Usuário e Senha:"],"metadata":{"id":"Cvjvmb2qyjIS"}},{"cell_type":"markdown","source":["Vamos utilizar a biblioteca getpass para manter o usuário e a senha. Se precisar escrever um programa que leia do teclado a senha do usuário e não quer que ela seja ecoada, isto é, não seja visível, use o módulo getpass."],"metadata":{"id":"SNlHu9Nwylma"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxIvqg2JxGQ8"},"outputs":[],"source":["usermail = getpass()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3wfunjuSxGQ8"},"outputs":[],"source":["senha = getpass()"]},{"cell_type":"markdown","source":["## Preenchendo o Formulário de Login:"],"metadata":{"id":"vkTnPzJyzGy8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLZeAx0oxGRA"},"outputs":[],"source":["# Preenchendo o usuário\n","element_login = driver.find_element_by_xpath('//*[@id=\"session_key\"]')\n","element_login.clear()\n","element_login.send_keys(usermail)\n","\n","sleep(2)\n","\n","# Preenchendo a senha\n","element_senha = driver.find_element_by_xpath('//*[@id=\"session_password\"]')\n","element_senha.clear()\n","element_senha.send_keys(senha)\n","\n","sleep(2)\n","\n","# Clicar para entrar no linkedin\n","driver.find_element_by_xpath('//*[@id=\"main-content\"]/section[1]/div/div/form/button').click()"]},{"cell_type":"markdown","source":["## Rodando o Crawler:"],"metadata":{"id":"t5tD869pzZ-1"}},{"cell_type":"markdown","source":["Para entender como funciona o Crawler, é necessário entender os elementos da página.\n","\n","Ao entrarmos na página de funcionários da empresa, notamos que podem exister até 100 páginas (limitação do linkedin) com até 10 resultados de pesquisa (funcionários) por página.\n","\n","Sendo assim, é necessário que (1) o Crawler percorra todas as páginas e (2) percorra todos os resultados de cada página.\n","\n","Para fazer isso, utilizaremos 2 laços `for`:\n","\n","*   O primeiro laço é utilizado para alterar as paginas em um range de 1 a 101 (limite de páginas de pesquisa). Note que, na URL, existe um elemento `&page=` seguido de uma string(i), que será o elemento iterado no laço for. Isto é o que vai permitir mudarmos as páginas em cada iteração.\n","\n","*   O seguindo laço é necessário para alterar os 'cards' de cada funcionário. A iteração acontece diretamente dentro do XPATH, exatamente no elemento que altera entre um card e outro.\n","\n","*   Utilizamos ainda TRY e EXCEPT para, caso haja algum erro, o laço não seja quebrado e continue para a próxima iteração.\n","\n"],"metadata":{"id":"dvBOg84Lzzo5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BlZF4iUbxGRC"},"outputs":[],"source":["nomes = []\n","titulos = []\n","cidades = []\n","urls = []\n","\n","for i in range (1,101):\n","    driver.get('https://www.linkedin.com/search/results/people/?currentCompany=%5B\"202691\"%5D&origin=COMPANY_PAGE_CANNED_SEARCH&page='+str(i)+'&sid=38%3A')\n","    for j in range (1,11):\n","        try:\n","            nomes.append(driver.find_element_by_xpath('//*[@id=\"main\"]/div/div/div/ul/li['+str(j)+']/div/div/div[2]/div[1]/div[1]/div/span[1]/span/a/span/span[1]').text)\n","            titulos.append(driver.find_element_by_xpath('//*[@id=\"main\"]/div/div/div/ul/li['+str(j)+']/div/div/div[2]/div[1]/div[2]/div/div[1]').text)\n","            cidades.append(driver.find_element_by_xpath('//*[@id=\"main\"]/div/div/div/ul/li['+str(j)+']/div/div/div[2]/div[1]/div[2]/div/div[2]').text)\n","            urls.append(driver.find_element_by_xpath('//*[@id=\"main\"]/div/div/div/ul/li['+str(j)+']/div/div/div[2]/div[1]/div[1]/div/span[1]/span/a').get_attribute('href'))\n","        except:\n","            nomes.append('N/A')\n","            titulos.append('N/A')\n","            cidades.append('N/A')\n","            urls.append('N/A')\n","\n","    sleep(5)\n","    "]},{"cell_type":"markdown","source":["## Criando o Dataframe"],"metadata":{"id":"Pu8AiDWe1xI9"}},{"cell_type":"markdown","source":["Por fim, utilizamos as listas criadas no passo anterior para criar e exportar um dataframe em CSV, para ser utilizado em outras ferramentas, como Excel ou Power BI."],"metadata":{"id":"ALE7rwC110PG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N691gXn4xGRD"},"outputs":[],"source":["frame = list(zip(nomes, titulos, cidades, urls))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo8YRs29xGRD"},"outputs":[],"source":["df = pd.DataFrame(frame, columns = ['Nomes', 'Titulos', 'Cidades', 'URLs_Perfil'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OoKUXyr-xGRE"},"outputs":[],"source":["df.to_csv('lista-de-perfis.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnyiZTKDxGRE"},"outputs":[],"source":["# Fechando o navegador\n","\n","driver.quit()"]}],"metadata":{"interpreter":{"hash":"39388528d72888fbbba03322cc403966acc0238d838510611f612e3de2642a5b"},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}